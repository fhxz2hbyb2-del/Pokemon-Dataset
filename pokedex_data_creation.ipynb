{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0119ebf9-9583-43f1-b7bd-f47fedbc7949",
   "metadata": {},
   "source": [
    "# Reproducible code for creating a Pokémon Dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb39839-16ca-4fec-9d5d-85f233623220",
   "metadata": {},
   "source": [
    "This notebook downloads Pokémon data from the PokéAPI and stores this in one CSV-file that contains the **ID**, **Name**, **Type(s)**, **Description/Document**, **Filename**, **Tokens**, \n",
    "**Lemmas**, **POS**, **Proper Nouns** and **Named Entities**. \n",
    "\n",
    "All steps containing the proces of making the dataset can be reproduced by running the following cells top to bottom.\n",
    "Let's start with our imports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a8b92-6f4c-4c8d-ad83-6b5ebb162fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import unicodedata\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8dfb77-c6eb-47e4-94e2-7c1d6aae9091",
   "metadata": {},
   "source": [
    "Next, we set up our folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce77839-38f3-4868-b50b-ccc74b505bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49347fd2-3786-40e1-a425-80457f6c34a0",
   "metadata": {},
   "source": [
    "Request Pokémon data from the API: a loop runs from 1 to 1025 (the official Pokémon count up to Generation 9). The outcome of this loop will contain: \n",
    "- Pokémon ID\n",
    "- Pokémon name\n",
    "- Pokémon type\n",
    "- English Pokémon description \n",
    "- The name of the corresponding file <a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1)  \n",
    "\n",
    "<blockquote> If the request fails, it retries up to 3 times. If it still fails, it skips that Pokémon and moves to the next. </blockquote>\n",
    "\n",
    "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1) The code below will also create a folder with seperate .txt-files with names 0001_bulbasaur.txt, 0002_ivysaur.txt, etc., containing the descriptions of the Pokémon. These will be stored as 'data' and will be reffered to in the CSV-file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcba98-d005-4a20-b3db-38c331ef59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_data = []\n",
    "data_folder = \"pokedata\"\n",
    "os.makedirs(data_folder, exist_ok=True) \n",
    "\n",
    "for i in range(1, 1026):\n",
    "    print(f\"Getting Pokémon {i}...\")  # to see what the downloading status is \n",
    "\n",
    "    for attempt in range(3):\n",
    "        p_resp = requests.get(f\"https://pokeapi.co/api/v2/pokemon/{i}\")\n",
    "        if p_resp.status_code == 200:\n",
    "            break\n",
    "        print(f\"Retry {attempt+1} for Pokémon {i} (status {p_resp.status_code})\")\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        print(f\"Skipping Pokémon {i} after 3 failed attempts\")  #retry to get info up to 3 times \n",
    "        continue\n",
    "\n",
    "    p = p_resp.json()\n",
    "\n",
    "    for attempt in range(3):\n",
    "        s_resp = requests.get(f\"https://pokeapi.co/api/v2/pokemon-species/{i}\")\n",
    "        if s_resp.status_code == 200:\n",
    "            break\n",
    "        print(f\"Retry {attempt+1} for species {i} (status {s_resp.status_code})\")\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        print(f\"Skipping species {i} after 3 failed attempts\")\n",
    "        continue\n",
    "\n",
    "    s = s_resp.json()\n",
    "\n",
    "    english_entries = [\n",
    "        e['flavor_text'].replace(\"\\n\", \" \").replace(\"\\x0c\", \" \")\n",
    "        for e in s['flavor_text_entries']\n",
    "        if e['language']['name'] == 'en'\n",
    "    ]\n",
    "    description = english_entries[0] if english_entries else \"\"\n",
    "\n",
    "    filename = f\"{i:04d}_{p['name']}.txt\"\n",
    "    with open(os.path.join(data_folder, filename), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(description)\n",
    "\n",
    "    pokemon_data.append({\n",
    "        \"id\": i,\n",
    "        \"name\": p['name'],\n",
    "        \"types\": [t['type']['name'] for t in p['types']],\n",
    "        \"description\": description,\n",
    "        \"filename\": filename\n",
    "    })\n",
    "\n",
    "    time.sleep(0.3)  # delay to avoid overload\n",
    "\n",
    "print(f\"\\nAll done! Successfully collected data for {len(pokemon_data)} Pokémon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463092d-599b-4a7c-8118-d9827f477f99",
   "metadata": {},
   "source": [
    "Now we convert the list into a dataframe using Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a950610-afdb-4ea7-9737-bc0b17d5c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pokemon_data)\n",
    "df.to_csv(\"pokedex.csv\", index=False)\n",
    "print(\"CSV saved as 'pokedex.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5eb376-3cca-4d09-a6be-122c045960af",
   "metadata": {},
   "source": [
    "As a final step, we load a SpaCy English model and clean the Pokémon descriptions, so that they can be annotated with **tokens**, **lemmas**, **parts of speech**, **proper nouns**, and **named entities**. The POS tags are explained in a separate column, and intermediate data is removed before saving the fully annotated CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552330a0-602c-46fb-a10a-abfaa8470910",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "df = pd.read_csv(\"pokedex.csv\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"description\"].apply(preprocess_text)\n",
    "\n",
    "# Run SpaCy pipeline\n",
    "df[\"doc\"] = df[\"clean_text\"].apply(nlp)\n",
    "\n",
    "df[\"tokens\"] = df[\"doc\"].apply(lambda doc: [t.text for t in doc])\n",
    "df[\"lemmas\"] = df[\"doc\"].apply(lambda doc: [t.lemma_ for t in doc])\n",
    "df[\"pos_tags\"] = df[\"doc\"].apply(\n",
    "    lambda doc: [(t.text, t.tag_, spacy.explain(t.tag_)) for t in doc]\n",
    ")\n",
    "df[\"proper_nouns\"] = df[\"doc\"].apply(\n",
    "    lambda doc: [t.text for t in doc if t.pos_ == \"PROPN\"]\n",
    ")\n",
    "df[\"named_entities\"] = df[\"doc\"].apply(\n",
    "    lambda doc: [(ent.text, ent.label_) for ent in doc.ents]\n",
    ")\n",
    "\n",
    "df = df.drop(columns=[\"doc\", \"clean_text\"])\n",
    "df.to_csv(\"pokedex_annotated.csv\", index=False)\n",
    "\n",
    "print(f\"All done! Annotated data saved as 'pokedex_annotated.csv' ({len(df)} Pokémon).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa3353-f69f-4d42-8805-8984a275ee66",
   "metadata": {},
   "source": [
    "# Bonus: some small initial analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb373e9-a9fb-4fba-8648-51adf9a267cf",
   "metadata": {},
   "source": [
    "Within the dataset we have just created, there are many opportunities for further analysis. To illustrate this, the following section outlines several examples of analyses that can be performed using only the information contained in the dataset, without relying on any external data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad619a-38a5-43af-a8a6-40e16e75028b",
   "metadata": {},
   "source": [
    "## Most common words per Pokémon type\n",
    "This analysis lists the ten most frequent descriptive words for each Pokémon type. First, it loads the annotated CSV and converts the types and tokens columns from strings to lists. It explodes the types column so each Pokémon-type pair becomes a separate row, and removes any missing types. Custom stopwords, including 'pokémon' and 'body' are defined to avoid counting trivial words. Then, it iterates over each row, filtering tokens and updating a counter per type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad8f71-5fbc-44e8-9fbc-de15bfb24cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8e403-7907-4446-8317-536a7f193976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import ast\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "custom_stopwords = stopwords.union({\"pokemon\", \"pokémon\", \"pokémons\", \"body\"})\n",
    "\n",
    "df = pd.read_csv(\"pokedex_annotated.csv\")\n",
    "\n",
    "df[\"types\"] = df[\"types\"].apply(ast.literal_eval)\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(ast.literal_eval)\n",
    "df = df[df[\"tokens\"].apply(len) > 0]\n",
    "\n",
    "df = df.explode(\"types\")\n",
    "\n",
    "df = df[df[\"types\"].notna()]\n",
    "\n",
    "type_word_counts = defaultdict(Counter)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    poke_type = row[\"types\"]\n",
    "    tokens = [\n",
    "    t for t in row[\"tokens\"]\n",
    "    if t not in custom_stopwords and len(t) > 2\n",
    "]\n",
    "    type_word_counts[poke_type].update(tokens)\n",
    "\n",
    "for poke_type, counter in type_word_counts.items():\n",
    "    print(f\"\\n{poke_type} Pokémon:\")\n",
    "    for word, count in counter.most_common(10):\n",
    "        print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80905e-5599-45d5-bbec-17daa32d6fe6",
   "metadata": {},
   "source": [
    "We can visualise this using the WordCloud library, assigning words a size based on their frequency and a color corresponding to their Pokémon type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f50f0-4652-4726-a3d8-3e3677ad6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "type_colors = {\n",
    "    \"fire\": \"#E41A1C\",      # red\n",
    "    \"water\": \"#377EB8\",     # blue\n",
    "    \"grass\": \"#4DAF4A\",     # green\n",
    "    \"electric\": \"#FFD92F\",  # yellow\n",
    "    \"psychic\": \"#984EA3\",   # purple\n",
    "    \"rock\": \"#A65628\",      # brown\n",
    "    \"ground\": \"#D95F02\",    # orange\n",
    "    \"ice\": \"#A6CEE3\",       # light blue\n",
    "    \"dragon\": \"#1B9E77\",    # teal\n",
    "    \"fairy\": \"#F781BF\"      # pink\n",
    "}\n",
    "\n",
    "word_frequencies = {}\n",
    "word_to_type = {}\n",
    "\n",
    "for poke_type, counter in type_word_counts.items():\n",
    "    if poke_type not in type_colors:\n",
    "        continue\n",
    "\n",
    "    for word, count in counter.most_common(3):\n",
    "        word_frequencies[word] = count\n",
    "        word_to_type[word] = poke_type\n",
    "\n",
    "def color_func(word, *args, **kwargs):\n",
    "    return type_colors.get(word_to_type.get(word, \"\"), \"black\")\n",
    "\n",
    "wc = WordCloud(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    background_color=\"white\",\n",
    "    color_func=color_func\n",
    ").generate_from_frequencies(word_frequencies)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Top descriptive words per Pokémon type\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec303a3-8c2b-4e8d-8852-7c175b24241d",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "Sentiment analysis evaluates the tone of each Pokémon’s description using a sentiment analyzer (in this case, VADER). We calculate a sentiment score per Pokémon, where positive values indicate a positive description and negative values indicate a negative description. The code can then rank Pokémon by their sentiment to identify the most positive or negative ones and aggregate sentiment by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c2264-486b-4813-9b0e-486f2625039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df['sentiment'] = df['description'].apply(lambda x: sia.polarity_scores(str(x))['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45b292-a874-4183-a430-862bbb61253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "df = pd.read_csv(\"pokedex_annotated.csv\")\n",
    "\n",
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['description'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "\n",
    "top_positive = df.sort_values('sentiment', ascending=False).head(10)\n",
    "print(\"Top 10 most positive Pokémon:\")\n",
    "print(top_positive[['name', 'description', 'sentiment']])\n",
    "\n",
    "\n",
    "top_negative = df.sort_values('sentiment', ascending=True).head(10)\n",
    "print(\"\\nTop 10 most negative Pokémon:\")\n",
    "print(top_negative[['name', 'description', 'sentiment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb74c3-5241-4ca1-bc63-a11e9f1cab8c",
   "metadata": {},
   "source": [
    "We can also make a bar chart showing which Pokémon types tend to have more positive or negative descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab584663-7fb7-4e43-9274-5ac8064cd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "df = pd.read_csv(\"pokedex_annotated.csv\")\n",
    "df['types'] = df['types'].apply(ast.literal_eval)\n",
    "\n",
    "df['sentiment'] = df['description'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "\n",
    "# Explode the types to handle dual-types\n",
    "df_exploded = df.explode('types')\n",
    "\n",
    "type_sentiment = df_exploded.groupby('types')['sentiment'].mean().sort_values()\n",
    "\n",
    "# Color scale: red for negative, green for positive\n",
    "norm = mcolors.Normalize(vmin=type_sentiment.min(), vmax=type_sentiment.max())\n",
    "cmap = plt.cm.RdYlGn  # Red → Yellow → Green\n",
    "colors = [cmap(norm(val)) for val in type_sentiment.values]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(type_sentiment.index, type_sentiment.values, color=colors)\n",
    "plt.title(\"Average Sentiment per Pokémon Type\")\n",
    "plt.xlabel(\"Average Sentiment\")\n",
    "plt.ylabel(\"Pokémon Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4161fa-ed46-4e87-b20a-8face30f1a39",
   "metadata": {},
   "source": [
    "## Heatmap of type co-occurrences (for the dual-type Pokémon).\n",
    "There are Pokémon with exactly two types (dual-type Pokémon). We can investigate which types are most likely to co-occur by building a matric where rows and columns are all Pokémon types. In each cell, the number of Pokémon with that type combination is counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b572f0-9805-493c-9ade-7f7c699127a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"pokedex_annotated.csv\")\n",
    "df['types'] = df['types'].apply(ast.literal_eval)\n",
    "\n",
    "# Keep only Pokémon with 2 types\n",
    "dual_type_df = df[df['types'].apply(len) == 2]\n",
    "\n",
    "# All types\n",
    "all_types = sorted({t for sublist in df['types'] for t in sublist})\n",
    "\n",
    "co_matrix = pd.DataFrame(0, index=all_types, columns=all_types)\n",
    "for types in dual_type_df['types']:\n",
    "    t1, t2 = types\n",
    "    co_matrix.loc[t1, t2] += 1\n",
    "    co_matrix.loc[t2, t1] += 1  # symmetric\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "cax = ax.matshow(co_matrix, cmap='YlGnBu')  # color map\n",
    "\n",
    "fig.colorbar(cax, label='Co-occurrence count')\n",
    "\n",
    "ax.set_xticks(np.arange(len(all_types)))\n",
    "ax.set_yticks(np.arange(len(all_types)))\n",
    "ax.set_xticklabels(all_types, rotation=45, ha='right')\n",
    "ax.set_yticklabels(all_types)\n",
    "\n",
    "# Add counts inside cells\n",
    "for i in range(len(all_types)):\n",
    "    for j in range(len(all_types)):\n",
    "        count = co_matrix.iloc[i, j]\n",
    "        if count > 0:\n",
    "            ax.text(j, i, str(count), va='center', ha='center', color='black')\n",
    "\n",
    "plt.title(\"Co-occurrence of Dual Pokémon Types\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
